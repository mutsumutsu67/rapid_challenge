{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb5069b",
   "metadata": {},
   "source": [
    "# Stage4 深層学習day3\n",
    "\n",
    "## 深層学習day3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d20c7f",
   "metadata": {},
   "source": [
    "##  0、深層学習全体像の復習\n",
    "### &emsp;&emsp; 最新のCNN  (AlexNetを事例で紹介）\n",
    "### &emsp;&emsp; Stage3 Day2で説明を書いたので、ここでは省略\n",
    "\n",
    "#### 0.1　確認テスト:\n",
    "#### &emsp;&emsp; サイズ5×5の入力画像を、サイズ3×3のフィルタで畳み込んだ時の出力画像のサイズを答えよ。\n",
    "#### &emsp;&emsp; なおストライドは2、パディングは1とする。\n",
    "##### &emsp;&emsp; 　解答：3 x 3\n",
    "##### &emsp;&emsp;  計算式：\n",
    "##### &emsp;&emsp;  Oh = (画像の高さ + 2 x パディング数　- フィルターの高さ) / ストライド)+1\n",
    "##### &emsp;&emsp;  Oh = (5 + 2 x 1 - 3) / 2)+1  = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d47b695",
   "metadata": {},
   "source": [
    "##  １、Section1：再帰型ニューラルネットワークの概念\n",
    "###  &emsp;&emsp; 1.1　要点まとめ\n",
    "###  &emsp;&emsp; 1.1.1　RNN全体像\n",
    "####  &emsp;&emsp;&emsp;&emsp; RNNとは時系列データが処理出来るニューラルネットワークである。\n",
    "####  &emsp;&emsp;&emsp;&emsp; 時系列データとは時間的順序を持って一定間隔ごとに観察されるデータ群。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b02c9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_section1.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_section1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c54a68",
   "metadata": {},
   "source": [
    "###  &emsp;&emsp; 1.1.2　BPTT（Back-Propagation Through Time）\n",
    "#### &emsp;&emsp;&emsp;  RNNでの逆誤差伝搬法です。\n",
    "#### &emsp;&emsp;&emsp;&emsp; $ u^t = W_{(in} x^t + W z^{t-1} + b $\n",
    "#### &emsp;&emsp;&emsp;&emsp; $ z^t = f( W_{(in} x^t + W z^{t-1} + b ) $\n",
    "#### &emsp;&emsp;&emsp;&emsp; $ v^t = W_{(out)} z^{t} + c $\n",
    "#### &emsp;&emsp;&emsp;&emsp; $ y^t = g(W_{(out)}z^t + c ) $\n",
    "#### &emsp;&emsp;&emsp;\n",
    "#### &emsp;&emsp;&emsp;&emsp; $ E^t = loss ( y^t , d^t ) $\n",
    "#### &emsp;&emsp; RNNの課題\n",
    "#### &emsp;&emsp; &emsp; 時系列を遡れば遡るほど、勾配が消失していく。勾配消失問題を持っている。\n",
    "#### &emsp;&emsp; &emsp; （これはCNNと同じ。微分が繰り返されるから）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f7f88",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 1.2　実装演習結果と考察\n",
    "####  &emsp;&emsp; 1.2.1　実装演習結果 (3_1_simple_RNN.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee2e725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sectino1_3_1_simple_RNN_handson.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sectino1_3_1_simple_RNN_handson.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50d4a1",
   "metadata": {},
   "source": [
    "##### ハンズオン中の試してみようを実施しました。\n",
    "##### [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132610b",
   "metadata": {},
   "source": [
    "##### [try] 重みの初期化方法を変更してみよう\n",
    "##### &emsp;&emsp;&emsp;Xavier, He"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b110c0",
   "metadata": {},
   "source": [
    "##### [try] 中間層の活性化関数を変更してみよう\n",
    "##### &emsp;&emsp;&emsp;ReLU(勾配爆発を確認しよう)\n",
    "##### &emsp;&emsp;&emsp;tanh(numpyにtanhが用意されている。導関数をd_tanhとして作成しよう)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b8a61",
   "metadata": {},
   "source": [
    "#####  [try] sigmoid - He と relu - Xavier についても試してみよう(結果のみ表示）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb1e0e",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 1.2.1　実装演習結果 (3_1_simple_RNN.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ede9b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sectino1_3_1_simple_RNN_handson.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sectino1_3_1_simple_RNN_handson.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae3535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:0\n",
      "Loss:2.2605469401456477\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 0 1 0 0]\n",
      "52 + 0 = 255\n",
      "------------\n",
      "iters:100\n",
      "Loss:0.8771328604318622\n",
      "Pred:[1 1 1 0 0 1 1 1]\n",
      "True:[1 1 1 1 0 0 0 1]\n",
      "114 + 127 = 231\n",
      "------------\n",
      "iters:200\n",
      "Loss:1.2612702889749918\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "99 + 49 = 99\n",
      "------------\n",
      "iters:300\n",
      "Loss:1.0793945457354608\n",
      "Pred:[1 0 0 1 0 0 0 0]\n",
      "True:[1 0 1 0 1 1 0 0]\n",
      "75 + 97 = 144\n",
      "------------\n",
      "iters:400\n",
      "Loss:0.9235345369902079\n",
      "Pred:[0 0 0 0 0 0 0 1]\n",
      "True:[0 1 1 1 1 0 0 1]\n",
      "96 + 25 = 1\n",
      "------------\n",
      "iters:500\n",
      "Loss:1.0963228635899016\n",
      "Pred:[0 0 0 0 0 0 0 1]\n",
      "True:[0 1 1 0 0 1 1 1]\n",
      "79 + 24 = 1\n",
      "------------\n",
      "iters:600\n",
      "Loss:1.0146802674611117\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 0 1 1 0 1 1 0]\n",
      "47 + 7 = 110\n",
      "------------\n",
      "iters:700\n",
      "Loss:0.8812377912668143\n",
      "Pred:[0 1 0 0 0 0 0 0]\n",
      "True:[0 1 0 0 1 1 1 0]\n",
      "34 + 44 = 64\n",
      "------------\n",
      "iters:800\n",
      "Loss:0.8986920542973698\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 1 0 1 1 0 1]\n",
      "106 + 67 = 255\n",
      "------------\n",
      "iters:900\n",
      "Loss:0.9725533489723746\n",
      "Pred:[1 1 1 1 1 0 1 0]\n",
      "True:[0 1 1 1 1 1 0 0]\n",
      "97 + 27 = 250\n",
      "------------\n",
      "iters:1000\n",
      "Loss:0.7879274290138727\n",
      "Pred:[0 1 0 1 1 0 0 0]\n",
      "True:[0 1 0 1 1 1 1 0]\n",
      "41 + 53 = 88\n",
      "------------\n",
      "iters:1100\n",
      "Loss:1.0604328990549359\n",
      "Pred:[1 1 1 1 1 1 1 0]\n",
      "True:[1 0 1 0 0 1 1 0]\n",
      "120 + 46 = 254\n",
      "------------\n",
      "iters:1200\n",
      "Loss:0.8047884648956727\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[1 0 1 1 0 1 1 1]\n",
      "117 + 66 = 191\n",
      "------------\n",
      "iters:1300\n",
      "Loss:1.0923769223250144\n",
      "Pred:[0 1 0 0 1 0 0 1]\n",
      "True:[0 1 1 1 0 1 0 1]\n",
      "63 + 54 = 73\n",
      "------------\n",
      "iters:1400\n",
      "Loss:1.1502321315529278\n",
      "Pred:[1 1 1 0 1 1 1 0]\n",
      "True:[1 1 1 1 0 0 0 0]\n",
      "113 + 127 = 238\n",
      "------------\n",
      "iters:1500\n",
      "Loss:1.0881460117052106\n",
      "Pred:[0 1 1 1 1 0 1 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "102 + 29 = 123\n",
      "------------\n",
      "iters:1600\n",
      "Loss:0.6892445820800092\n",
      "Pred:[0 1 0 0 1 0 0 1]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "56 + 49 = 73\n",
      "------------\n",
      "iters:1700\n",
      "Loss:1.171446008390266\n",
      "Pred:[0 1 0 0 1 0 0 1]\n",
      "True:[1 0 1 1 0 0 0 1]\n",
      "53 + 124 = 73\n",
      "------------\n",
      "iters:1800\n",
      "Loss:1.1186748385701206\n",
      "Pred:[0 1 0 0 0 1 0 1]\n",
      "True:[1 0 1 1 0 0 0 1]\n",
      "55 + 122 = 69\n",
      "------------\n",
      "iters:1900\n",
      "Loss:0.8396528025656786\n",
      "Pred:[0 0 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 0 0 1]\n",
      "47 + 10 = 63\n",
      "------------\n",
      "iters:2000\n",
      "Loss:1.0259891534844905\n",
      "Pred:[0 0 1 0 1 0 0 0]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "71 + 43 = 40\n",
      "------------\n",
      "iters:2100\n",
      "Loss:0.9095587761267676\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "93 + 21 = 126\n",
      "------------\n",
      "iters:2200\n",
      "Loss:1.0725761293227407\n",
      "Pred:[1 0 1 0 0 0 1 0]\n",
      "True:[1 1 0 1 0 1 0 0]\n",
      "123 + 89 = 162\n",
      "------------\n",
      "iters:2300\n",
      "Loss:0.9094997845464078\n",
      "Pred:[1 1 1 1 1 0 1 0]\n",
      "True:[0 1 1 1 1 1 0 0]\n",
      "105 + 19 = 250\n",
      "------------\n",
      "iters:2400\n",
      "Loss:0.8664695537302247\n",
      "Pred:[1 0 1 0 0 0 0 1]\n",
      "True:[1 1 0 1 0 0 0 1]\n",
      "120 + 89 = 161\n",
      "------------\n",
      "iters:2500\n",
      "Loss:0.9383731319075581\n",
      "Pred:[0 1 0 0 0 1 0 1]\n",
      "True:[1 0 1 0 1 1 0 1]\n",
      "61 + 112 = 69\n",
      "------------\n",
      "iters:2600\n",
      "Loss:0.5530014317681884\n",
      "Pred:[1 1 1 1 0 1 0 1]\n",
      "True:[0 1 1 1 0 1 0 1]\n",
      "100 + 17 = 245\n",
      "------------\n",
      "iters:2700\n",
      "Loss:1.227366718024506\n",
      "Pred:[0 1 1 1 0 0 0 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "92 + 45 = 113\n",
      "------------\n",
      "iters:2800\n",
      "Loss:0.7869795363464555\n",
      "Pred:[1 0 0 0 1 0 1 1]\n",
      "True:[1 1 1 0 1 0 1 1]\n",
      "115 + 120 = 139\n",
      "------------\n",
      "iters:2900\n",
      "Loss:1.036331980898103\n",
      "Pred:[0 1 0 0 1 1 0 1]\n",
      "True:[1 0 1 0 0 0 0 1]\n",
      "58 + 103 = 77\n",
      "------------\n",
      "iters:3000\n",
      "Loss:0.4521753794451177\n",
      "Pred:[0 1 1 1 0 1 1 0]\n",
      "True:[0 1 1 0 0 1 1 0]\n",
      "14 + 88 = 118\n",
      "------------\n",
      "iters:3100\n",
      "Loss:0.6313275534350115\n",
      "Pred:[0 0 1 1 0 0 0 1]\n",
      "True:[0 1 1 1 0 0 0 1]\n",
      "110 + 3 = 49\n",
      "------------\n",
      "iters:3200\n",
      "Loss:1.0876769256926024\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[1 0 0 0 1 1 1 0]\n",
      "23 + 119 = 110\n",
      "------------\n",
      "iters:3300\n",
      "Loss:0.22826671761882208\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "86 + 24 = 110\n",
      "------------\n",
      "iters:3400\n",
      "Loss:0.6024738522639637\n",
      "Pred:[1 1 0 0 0 0 1 0]\n",
      "True:[1 0 0 0 0 1 1 0]\n",
      "72 + 62 = 194\n",
      "------------\n",
      "iters:3500\n",
      "Loss:0.3855304384457178\n",
      "Pred:[0 1 1 0 0 0 0 1]\n",
      "True:[0 1 1 1 0 0 0 1]\n",
      "61 + 52 = 97\n",
      "------------\n",
      "iters:3600\n",
      "Loss:0.2669610039550686\n",
      "Pred:[1 0 1 0 1 1 0 1]\n",
      "True:[1 0 1 0 1 1 0 1]\n",
      "70 + 103 = 173\n",
      "------------\n",
      "iters:3700\n",
      "Loss:0.28823044902494366\n",
      "Pred:[1 0 0 0 1 1 1 0]\n",
      "True:[1 0 0 0 1 1 1 0]\n",
      "45 + 97 = 142\n",
      "------------\n",
      "iters:3800\n",
      "Loss:0.3223266853011104\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "105 + 5 = 126\n",
      "------------\n",
      "iters:3900\n",
      "Loss:0.1836898065527694\n",
      "Pred:[0 1 0 0 1 0 1 0]\n",
      "True:[0 1 0 0 1 0 1 0]\n",
      "62 + 12 = 74\n",
      "------------\n",
      "iters:4000\n",
      "Loss:0.224400408281235\n",
      "Pred:[1 0 0 1 0 1 0 1]\n",
      "True:[1 0 0 1 0 1 0 1]\n",
      "102 + 47 = 149\n",
      "------------\n",
      "iters:4100\n",
      "Loss:0.13713644375231918\n",
      "Pred:[1 1 0 0 1 1 1 1]\n",
      "True:[1 1 0 0 1 1 1 1]\n",
      "117 + 90 = 207\n",
      "------------\n",
      "iters:4200\n",
      "Loss:0.12966861201646296\n",
      "Pred:[1 0 0 0 1 0 0 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "17 + 120 = 137\n",
      "------------\n",
      "iters:4300\n",
      "Loss:0.11370198296926862\n",
      "Pred:[0 1 0 1 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "30 + 53 = 83\n",
      "------------\n",
      "iters:4400\n",
      "Loss:0.09141749815829493\n",
      "Pred:[1 1 1 0 1 0 0 1]\n",
      "True:[1 1 1 0 1 0 0 1]\n",
      "127 + 106 = 233\n",
      "------------\n",
      "iters:4500\n",
      "Loss:0.036964705884386544\n",
      "Pred:[1 1 0 0 0 1 1 0]\n",
      "True:[1 1 0 0 0 1 1 0]\n",
      "117 + 81 = 198\n",
      "------------\n",
      "iters:4600\n",
      "Loss:0.08833801111727473\n",
      "Pred:[0 1 0 0 0 1 0 0]\n",
      "True:[0 1 0 0 0 1 0 0]\n",
      "11 + 57 = 68\n",
      "------------\n",
      "iters:4700\n",
      "Loss:0.01523504893034459\n",
      "Pred:[1 0 0 1 0 0 1 0]\n",
      "True:[1 0 0 1 0 0 1 0]\n",
      "105 + 41 = 146\n",
      "------------\n",
      "iters:4800\n",
      "Loss:0.01377856869711528\n",
      "Pred:[1 0 1 1 0 0 0 0]\n",
      "True:[1 0 1 1 0 0 0 0]\n",
      "92 + 84 = 176\n",
      "------------\n",
      "iters:4900\n",
      "Loss:0.04869990736231627\n",
      "Pred:[1 0 0 0 1 0 0 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "94 + 43 = 137\n",
      "------------\n",
      "iters:5000\n",
      "Loss:0.0046123939986919315\n",
      "Pred:[0 1 0 0 0 1 1 0]\n",
      "True:[0 1 0 0 0 1 1 0]\n",
      "52 + 18 = 70\n",
      "------------\n",
      "iters:5100\n",
      "Loss:0.028659991627098418\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[1 0 1 1 1 1 1 1]\n",
      "112 + 79 = 191\n",
      "------------\n",
      "iters:5200\n",
      "Loss:0.019137272627152962\n",
      "Pred:[1 0 1 0 0 1 1 1]\n",
      "True:[1 0 1 0 0 1 1 1]\n",
      "45 + 122 = 167\n",
      "------------\n",
      "iters:5300\n",
      "Loss:0.008736731300436383\n",
      "Pred:[0 1 1 1 0 1 1 0]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "67 + 51 = 118\n",
      "------------\n",
      "iters:5400\n",
      "Loss:0.012653761158267234\n",
      "Pred:[0 1 1 0 1 0 1 1]\n",
      "True:[0 1 1 0 1 0 1 1]\n",
      "8 + 99 = 107\n",
      "------------\n",
      "iters:5500\n",
      "Loss:0.016828965159315045\n",
      "Pred:[0 0 0 1 1 0 0 1]\n",
      "True:[0 0 0 1 1 0 0 1]\n",
      "14 + 11 = 25\n",
      "------------\n",
      "iters:5600\n",
      "Loss:0.0021453006504289205\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "13 + 97 = 110\n",
      "------------\n",
      "iters:5700\n",
      "Loss:0.01917858235597625\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "98 + 31 = 129\n",
      "------------\n",
      "iters:5800\n",
      "Loss:0.004229889830846091\n",
      "Pred:[1 0 0 1 1 1 1 0]\n",
      "True:[1 0 0 1 1 1 1 0]\n",
      "49 + 109 = 158\n",
      "------------\n",
      "iters:5900\n",
      "Loss:0.0016585615145863124\n",
      "Pred:[0 0 0 1 1 1 1 1]\n",
      "True:[0 0 0 1 1 1 1 1]\n",
      "29 + 2 = 31\n",
      "------------\n",
      "iters:6000\n",
      "Loss:0.014600644062672282\n",
      "Pred:[1 0 0 0 1 1 0 0]\n",
      "True:[1 0 0 0 1 1 0 0]\n",
      "93 + 47 = 140\n",
      "------------\n",
      "iters:6100\n",
      "Loss:0.0011877061446530402\n",
      "Pred:[0 0 1 0 0 0 0 0]\n",
      "True:[0 0 1 0 0 0 0 0]\n",
      "31 + 1 = 32\n",
      "------------\n",
      "iters:6200\n",
      "Loss:0.006787753081612912\n",
      "Pred:[1 1 0 0 0 0 0 0]\n",
      "True:[1 1 0 0 0 0 0 0]\n",
      "79 + 113 = 192\n",
      "------------\n",
      "iters:6300\n",
      "Loss:0.016755832908470495\n",
      "Pred:[1 0 0 0 1 1 0 1]\n",
      "True:[1 0 0 0 1 1 0 1]\n",
      "46 + 95 = 141\n",
      "------------\n",
      "iters:6400\n",
      "Loss:0.0062517232312610735\n",
      "Pred:[1 0 0 0 0 1 1 1]\n",
      "True:[1 0 0 0 0 1 1 1]\n",
      "58 + 77 = 135\n",
      "------------\n",
      "iters:6500\n",
      "Loss:0.0013576603676041276\n",
      "Pred:[0 1 0 1 1 1 0 1]\n",
      "True:[0 1 0 1 1 1 0 1]\n",
      "9 + 84 = 93\n",
      "------------\n",
      "iters:6600\n",
      "Loss:0.0022796220267466516\n",
      "Pred:[0 1 0 0 0 1 1 0]\n",
      "True:[0 1 0 0 0 1 1 0]\n",
      "12 + 58 = 70\n",
      "------------\n",
      "iters:6700\n",
      "Loss:0.0010680727031087004\n",
      "Pred:[1 0 1 1 1 1 0 0]\n",
      "True:[1 0 1 1 1 1 0 0]\n",
      "107 + 81 = 188\n",
      "------------\n",
      "iters:6800\n",
      "Loss:0.0008759019612559512\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "96 + 14 = 110\n",
      "------------\n",
      "iters:6900\n",
      "Loss:0.003756570378935506\n",
      "Pred:[1 0 1 1 1 0 1 0]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "99 + 87 = 186\n",
      "------------\n",
      "iters:7000\n",
      "Loss:0.004845805275288967\n",
      "Pred:[1 0 1 0 1 0 0 0]\n",
      "True:[1 0 1 0 1 0 0 0]\n",
      "77 + 91 = 168\n",
      "------------\n",
      "iters:7100\n",
      "Loss:0.0024209161311512235\n",
      "Pred:[0 1 1 1 0 1 1 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "86 + 33 = 119\n",
      "------------\n",
      "iters:7200\n",
      "Loss:0.0025963211357000375\n",
      "Pred:[0 0 1 1 1 1 0 0]\n",
      "True:[0 0 1 1 1 1 0 0]\n",
      "17 + 43 = 60\n",
      "------------\n",
      "iters:7300\n",
      "Loss:0.003618873092085769\n",
      "Pred:[1 0 0 0 0 1 1 1]\n",
      "True:[1 0 0 0 0 1 1 1]\n",
      "60 + 75 = 135\n",
      "------------\n",
      "iters:7400\n",
      "Loss:0.003951915833137545\n",
      "Pred:[0 1 1 1 1 0 1 1]\n",
      "True:[0 1 1 1 1 0 1 1]\n",
      "4 + 119 = 123\n",
      "------------\n",
      "iters:7500\n",
      "Loss:0.0015479940365740682\n",
      "Pred:[1 0 1 0 1 0 0 1]\n",
      "True:[1 0 1 0 1 0 0 1]\n",
      "99 + 70 = 169\n",
      "------------\n",
      "iters:7600\n",
      "Loss:0.0015883400953475124\n",
      "Pred:[1 0 0 0 1 0 1 1]\n",
      "True:[1 0 0 0 1 0 1 1]\n",
      "63 + 76 = 139\n",
      "------------\n",
      "iters:7700\n",
      "Loss:0.0016462502272717107\n",
      "Pred:[1 0 1 0 0 1 1 0]\n",
      "True:[1 0 1 0 0 1 1 0]\n",
      "57 + 109 = 166\n",
      "------------\n",
      "iters:7800\n",
      "Loss:0.002710617068469541\n",
      "Pred:[1 0 0 0 1 1 1 1]\n",
      "True:[1 0 0 0 1 1 1 1]\n",
      "90 + 53 = 143\n",
      "------------\n",
      "iters:7900\n",
      "Loss:0.0015711713811494756\n",
      "Pred:[1 1 0 1 1 0 0 0]\n",
      "True:[1 1 0 1 1 0 0 0]\n",
      "107 + 109 = 216\n",
      "------------\n",
      "iters:8000\n",
      "Loss:0.0010921054253734952\n",
      "Pred:[0 0 1 1 1 0 1 0]\n",
      "True:[0 0 1 1 1 0 1 0]\n",
      "47 + 11 = 58\n",
      "------------\n",
      "iters:8100\n",
      "Loss:0.0034082647826700185\n",
      "Pred:[0 1 0 0 1 1 0 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "26 + 51 = 77\n",
      "------------\n",
      "iters:8200\n",
      "Loss:0.0008107744356707905\n",
      "Pred:[1 1 0 0 0 1 1 1]\n",
      "True:[1 1 0 0 0 1 1 1]\n",
      "101 + 98 = 199\n",
      "------------\n",
      "iters:8300\n",
      "Loss:0.0007196775735718483\n",
      "Pred:[0 1 1 1 1 0 0 1]\n",
      "True:[0 1 1 1 1 0 0 1]\n",
      "45 + 76 = 121\n",
      "------------\n",
      "iters:8400\n",
      "Loss:0.002338567594684208\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 1 1 1]\n",
      "116 + 11 = 127\n",
      "------------\n",
      "iters:8500\n",
      "Loss:0.0004643030915615908\n",
      "Pred:[0 1 1 1 1 0 1 0]\n",
      "True:[0 1 1 1 1 0 1 0]\n",
      "53 + 69 = 122\n",
      "------------\n",
      "iters:8600\n",
      "Loss:0.000784240198561315\n",
      "Pred:[1 1 0 1 0 0 0 0]\n",
      "True:[1 1 0 1 0 0 0 0]\n",
      "123 + 85 = 208\n",
      "------------\n",
      "iters:8700\n",
      "Loss:0.001707756949423214\n",
      "Pred:[1 0 1 0 1 1 0 1]\n",
      "True:[1 0 1 0 1 1 0 1]\n",
      "100 + 73 = 173\n",
      "------------\n",
      "iters:8800\n",
      "Loss:0.0004874158677547764\n",
      "Pred:[1 0 1 1 0 1 1 1]\n",
      "True:[1 0 1 1 0 1 1 1]\n",
      "113 + 70 = 183\n",
      "------------\n",
      "iters:8900\n",
      "Loss:0.00319442012457908\n",
      "Pred:[1 0 0 1 1 0 0 1]\n",
      "True:[1 0 0 1 1 0 0 1]\n",
      "26 + 127 = 153\n",
      "------------\n",
      "iters:9000\n",
      "Loss:0.0017522859722600014\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "112 + 19 = 131\n",
      "------------\n",
      "iters:9100\n",
      "Loss:0.001383730539151415\n",
      "Pred:[0 1 0 1 1 0 0 1]\n",
      "True:[0 1 0 1 1 0 0 1]\n",
      "20 + 69 = 89\n",
      "------------\n",
      "iters:9200\n",
      "Loss:0.001333739764537657\n",
      "Pred:[0 0 1 1 0 0 1 1]\n",
      "True:[0 0 1 1 0 0 1 1]\n",
      "10 + 41 = 51\n",
      "------------\n",
      "iters:9300\n",
      "Loss:0.0005552455343994639\n",
      "Pred:[1 1 0 1 1 1 1 1]\n",
      "True:[1 1 0 1 1 1 1 1]\n",
      "103 + 120 = 223\n",
      "------------\n",
      "iters:9400\n",
      "Loss:0.00029357166531488425\n",
      "Pred:[0 1 1 0 1 1 0 1]\n",
      "True:[0 1 1 0 1 1 0 1]\n",
      "77 + 32 = 109\n",
      "------------\n",
      "iters:9500\n",
      "Loss:0.0013522157361188238\n",
      "Pred:[1 0 1 0 1 1 0 0]\n",
      "True:[1 0 1 0 1 1 0 0]\n",
      "101 + 71 = 172\n",
      "------------\n",
      "iters:9600\n",
      "Loss:0.0010985522071112683\n",
      "Pred:[1 1 0 0 0 0 1 1]\n",
      "True:[1 1 0 0 0 0 1 1]\n",
      "98 + 97 = 195\n",
      "------------\n",
      "iters:9700\n",
      "Loss:0.002032705469599083\n",
      "Pred:[1 1 1 1 1 0 0 1]\n",
      "True:[1 1 1 1 1 0 0 1]\n",
      "124 + 125 = 249\n",
      "------------\n",
      "iters:9800\n",
      "Loss:0.0003838700350133705\n",
      "Pred:[0 1 1 1 1 1 0 0]\n",
      "True:[0 1 1 1 1 1 0 0]\n",
      "38 + 86 = 124\n",
      "------------\n",
      "iters:9900\n",
      "Loss:0.0003821206255952687\n",
      "Pred:[0 1 0 1 0 1 1 1]\n",
      "True:[0 1 0 1 0 1 1 1]\n",
      "11 + 76 = 87\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "## sys.path.append('/content/drive/My Drive/DNN_code')\n",
    "sys.path.append('D:\\stage3_data\\DNN_code_colab_lesson_3_4')\n",
    "sys.path.append('D:\\stage3_data\\DNN_code_colab_lesson_1_2')\n",
    "\n",
    "import numpy as np\n",
    "from common import functions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def d_tanh(x):\n",
    "    return 1/(np.cosh(x) ** 2)\n",
    "\n",
    "# データを用意\n",
    "# 2進数の桁数\n",
    "binary_dim = 8\n",
    "# 最大値 + 1\n",
    "largest_number = pow(2, binary_dim)\n",
    "# largest_numberまで2進数を用意\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "\n",
    "input_layer_size = 2\n",
    "hidden_layer_size = 16\n",
    "output_layer_size = 1\n",
    "\n",
    "weight_init_std = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "iters_num = 10000\n",
    "plot_interval = 100\n",
    "\n",
    "# ウェイト初期化 (バイアスは簡単のため省略)\n",
    "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
    "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
    "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
    "# Xavier\n",
    "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
    "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
    "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
    "# He\n",
    "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
    "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
    "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
    "\n",
    "\n",
    "# 勾配\n",
    "W_in_grad = np.zeros_like(W_in)\n",
    "W_out_grad = np.zeros_like(W_out)\n",
    "W_grad = np.zeros_like(W)\n",
    "\n",
    "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "y = np.zeros((output_layer_size, binary_dim))\n",
    "\n",
    "delta_out = np.zeros((output_layer_size, binary_dim))\n",
    "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    # A, B初期化 (a + b = d)\n",
    "    a_int = np.random.randint(largest_number/2)\n",
    "    a_bin = binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2)\n",
    "    b_bin = binary[b_int] # binary encoding\n",
    "    \n",
    "    # 正解データ\n",
    "    d_int = a_int + b_int\n",
    "    d_bin = binary[d_int]\n",
    "    \n",
    "    # 出力バイナリ\n",
    "    out_bin = np.zeros_like(d_bin)\n",
    "    \n",
    "    # 時系列全体の誤差\n",
    "    all_loss = 0    \n",
    "    \n",
    "    # 時系列ループ\n",
    "    for t in range(binary_dim):\n",
    "        # 入力値\n",
    "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
    "        # 時刻tにおける正解データ\n",
    "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
    "        \n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
    "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
    "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
    "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
    "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
    "\n",
    "\n",
    "        #誤差\n",
    "        loss = functions.mean_squared_error(dd, y[:,t])\n",
    "        \n",
    "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
    "        \n",
    "        all_loss += loss\n",
    "\n",
    "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
    "    \n",
    "    \n",
    "    for t in range(binary_dim)[::-1]:\n",
    "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
    "\n",
    "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
    "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
    "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
    "\n",
    "        # 勾配更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "    \n",
    "    # 勾配適用\n",
    "    W_in -= learning_rate * W_in_grad\n",
    "    W_out -= learning_rate * W_out_grad\n",
    "    W -= learning_rate * W_grad\n",
    "    \n",
    "    W_in_grad *= 0\n",
    "    W_out_grad *= 0\n",
    "    W_grad *= 0\n",
    "    \n",
    "\n",
    "    if(i % plot_interval == 0):\n",
    "        all_losses.append(all_loss)        \n",
    "        print(\"iters:\" + str(i))\n",
    "        print(\"Loss:\" + str(all_loss))\n",
    "        print(\"Pred:\" + str(out_bin))\n",
    "        print(\"True:\" + str(d_bin))\n",
    "        out_int = 0\n",
    "        for index,x in enumerate(reversed(out_bin)):\n",
    "            out_int += x * pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
    "        print(\"------------\")\n",
    "\n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, all_losses, label=\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112bf51a",
   "metadata": {},
   "source": [
    "##### ハンズオン中の試してみようを実施しました。\n",
    "##### [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "206188b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "## sys.path.append('/content/drive/My Drive/DNN_code')\n",
    "sys.path.append('D:\\stage3_data\\DNN_code_colab_lesson_3_4')\n",
    "sys.path.append('D:\\stage3_data\\DNN_code_colab_lesson_1_2')\n",
    "\n",
    "import numpy as np\n",
    "from common import functions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def d_tanh(x):\n",
    "    return 1/(np.cosh(x) ** 2)\n",
    "\n",
    "# データを用意\n",
    "# 2進数の桁数\n",
    "##binary_dim = 8\n",
    "binary_dim = 8\n",
    "# 最大値 + 1\n",
    "largest_number = pow(2, binary_dim)\n",
    "# largest_numberまで2進数を用意\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "\n",
    "input_layer_size = 2\n",
    "## hidden_layer_size = 16\n",
    "hidden_layer_size = 16\n",
    "output_layer_size = 1\n",
    "\n",
    "weight_init_std = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "iters_num = 10000\n",
    "plot_interval = 100\n",
    "\n",
    "# ウェイト初期化 (バイアスは簡単のため省略)\n",
    "# W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
    "# W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
    "# W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
    "# Xavier\n",
    "## W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
    "## W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
    "## W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
    "# He\n",
    "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
    "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
    "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
    "\n",
    "\n",
    "# 勾配\n",
    "W_in_grad = np.zeros_like(W_in)\n",
    "W_out_grad = np.zeros_like(W_out)\n",
    "W_grad = np.zeros_like(W)\n",
    "\n",
    "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "y = np.zeros((output_layer_size, binary_dim))\n",
    "\n",
    "delta_out = np.zeros((output_layer_size, binary_dim))\n",
    "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    # A, B初期化 (a + b = d)\n",
    "    a_int = np.random.randint(largest_number/2)\n",
    "    a_bin = binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2)\n",
    "    b_bin = binary[b_int] # binary encoding\n",
    "    \n",
    "    # 正解データ\n",
    "    d_int = a_int + b_int\n",
    "    d_bin = binary[d_int]\n",
    "    \n",
    "    # 出力バイナリ\n",
    "    out_bin = np.zeros_like(d_bin)\n",
    "    \n",
    "    # 時系列全体の誤差\n",
    "    all_loss = 0    \n",
    "    \n",
    "    # 時系列ループ\n",
    "    for t in range(binary_dim):\n",
    "        # 入力値\n",
    "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
    "        # 時刻tにおける正解データ\n",
    "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
    "        \n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
    "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
    "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
    "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
    "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
    "\n",
    "\n",
    "        #誤差\n",
    "        loss = functions.mean_squared_error(dd, y[:,t])\n",
    "        \n",
    "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
    "        \n",
    "        all_loss += loss\n",
    "\n",
    "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
    "    \n",
    "    \n",
    "    for t in range(binary_dim)[::-1]:\n",
    "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
    "\n",
    "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
    "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
    "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
    "\n",
    "        # 勾配更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "    \n",
    "    # 勾配適用\n",
    "    W_in -= learning_rate * W_in_grad\n",
    "    W_out -= learning_rate * W_out_grad\n",
    "    W -= learning_rate * W_grad\n",
    "    \n",
    "    W_in_grad *= 0\n",
    "    W_out_grad *= 0\n",
    "    W_grad *= 0\n",
    "    \n",
    "\n",
    "    if(i % plot_interval == 0):\n",
    "        all_losses.append(all_loss)        \n",
    "##        print(\"iters:\" + str(i))\n",
    "##        print(\"Loss:\" + str(all_loss))\n",
    "##        print(\"Pred:\" + str(out_bin))\n",
    "##        print(\"True:\" + str(d_bin))\n",
    "        out_int = 0\n",
    "        for index,x in enumerate(reversed(out_bin)):\n",
    "            out_int += x * pow(2, index)\n",
    "##        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
    "##        print(\"------------\")\n",
    "\n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, all_losses, label=\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef073307",
   "metadata": {},
   "source": [
    "##### [try] 重みの初期化方法を変更してみよう\n",
    "##### &emsp;&emsp;&emsp;Xavier, He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd15539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/Stage4_day3_sction1_Xavier_He.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/Stage4_day3_sction1_Xavier_He.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48fde06",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 1.3　確認テスト\n",
    "##### 確認テスト①　RNNのネットワークには大きくわけて3つの重みがある。\n",
    "##### &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;1つは入力から現在の中間層を定義する際にかけられる重み、\n",
    "##### &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;1つは中間層から出力を定義する際にかけられる重みである。\n",
    "##### &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;残り1つの重みについて説明せよ。\n",
    "##### &emsp;&emsp;&emsp;&emsp; 解答：\n",
    "##### &emsp;&emsp;&emsp;&emsp; 前（の時間）の中間層からの重み\n",
    "\n",
    "##### 確認テスト②　連鎖律の原理を使い、dz/dxを求めよ。\n",
    "##### &emsp;&emsp;&emsp;&emsp; $z = t^ 2$\n",
    "##### &emsp;&emsp;&emsp;&emsp; $t = x + y $\n",
    "##### &emsp;&emsp;&emsp;&emsp; 解答：\n",
    "####    &emsp;&emsp; &emsp;&emsp; $ \\frac{\\partial z }{\\partial x} $ = $ \\frac{\\partial z}{\\partial t}$   $ \\frac{\\partial t}{\\partial x}$ \n",
    "####    &emsp;&emsp; &emsp;&emsp; $ \\frac{\\partial z }{\\partial t} $ = $ 2t$ ,  $ \\frac{\\partial t }{\\partial x} $ = $ 1 $ \n",
    "####    &emsp;&emsp; &emsp;&emsp; $ \\frac{\\partial z }{\\partial x} $ = $ 2(x + y )  $ \n",
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071b30b",
   "metadata": {},
   "source": [
    "### ２、Section2：LSTM全体像（前回の流れと課題全体像のビジョン）\n",
    "####  &emsp;&emsp; 2.1　要点まとめ\n",
    "####  &emsp;&emsp;&emsp;　RNNの勾配消失、勾配爆発を対応するために考えられた。\n",
    "####  &emsp;&emsp;CEC\n",
    "####  &emsp;&emsp;&emsp;勾配消失、勾配爆発問題の解消方法として勾配＝１の存在のメモリセル\n",
    "####  &emsp;&emsp;&emsp;勾配＝１なのでニューラルネットワークとしての学習機能がない。\n",
    "####  &emsp;&emsp;&emsp;そのためCECの周辺に学習機能を置くことになる。\n",
    "####  &emsp;&emsp;入力ゲート：CECに覚え方を教える\n",
    "####  &emsp;&emsp;出力ゲート：CECの出力をどんな風に使える（出力）（どの情報をどれだけ使うか）\n",
    "####  &emsp;&emsp;忘却ゲート：過去のデータが不要になったら削除する。（このゲートが無いと過去のデータは蓄積されたまま。）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc97afe",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 2.2　実装演習結果と考察\n",
    "####  &emsp;&emsp; ハンズオンはLSTMとGRUで共通。（GRUのsectionで記載）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f560d63",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 2.3　確認テスト\n",
    "##### &emsp;&emsp; 　確認テスト①  シグモイド関数を微分した時、入力値が0の時に最大値をとる。\n",
    "##### &emsp;&emsp; その値として正しいものを選択肢から選べ。\n",
    "##### &emsp;&emsp;&emsp;&emsp; 　（1）0.15（2）0.25（3）0.35（4）0.45\n",
    "##### &emsp;&emsp; 　解答：(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c9b6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "# シグモイド関数\n",
    "# y = 1 / (1 * + e^(-x))\n",
    "def sigmoid(a):\n",
    "    s = 1 / (1 + e**-a)\n",
    "    return s\n",
    "# シグモイド関数の微分\n",
    "# dy_sig = sigmoid(x) * (1 - sigmoid(x))\n",
    "def d_sigmoid(a):\n",
    "    s = sigmoid(a) * (1 - sigmoid(a))\n",
    "    return s\n",
    "e = math.e\n",
    "dx = 0.1\n",
    "x = np.arange(-10, 10, dx)\n",
    "y_sig = sigmoid(x)\n",
    "dy_sig = d_sigmoid(x)\n",
    "\n",
    "plt.plot(x, y_sig, label=\"sigmoid\")\n",
    "plt.plot(x, dy_sig, label=\"d_sigmoid\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde5517",
   "metadata": {},
   "source": [
    "###  ３、Section3：GRU\n",
    "####  &emsp;&emsp; 3.1　要点まとめ\n",
    "####  &emsp;&emsp;従来のLSTMがパラメータが多く計算量が多いので、精度を落とさず計算量を減らすことを\n",
    "####  &emsp;&emsp;目的につくられたのがGRUとなる。パラメータを大幅に削減したが精度が同等はまたは\n",
    "####  &emsp;&emsp;それ以上が望めるようになった。\n",
    "####  &emsp;&emsp;構成はリセットゲートと更新ゲートで成り立っており、\n",
    "####  &emsp;&emsp;更新ゲート：今の記憶を使ってどのような出力をするか。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c8ac4",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 3.2　実装演習結果と考察(predict_word.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import sys\n",
    "## sys.path.append('/content/drive/My Drive/DNN_code')\n",
    "sys.path.append('D:\\stage3_data\\DNN_code_colab_lesson_3_4')\n",
    "\n",
    "\n",
    "##### tensorflow_version 1.x 追加　\n",
    "tensorflow_version 1.x\n",
    "\n",
    "###### ディレクトリを移動\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('drive/My Drive/DNN_code_colab_lesson_3_4/lesson_3/3_2_tf_languagemodel/')\n",
    "\n",
    "\n",
    "###### predict_word\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import collections\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# logging levelを変更\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "class Corpus:\n",
    "    def __init__(self):\n",
    "        self.unknown_word_symbol = \"<???>\" # 出現回数の少ない単語は未知語として定義しておく\n",
    "        self.unknown_word_threshold = 3 # 未知語と定義する単語の出現回数の閾値\n",
    "        self.corpus_file = \"./corpus/**/*.txt\"\n",
    "        self.corpus_encoding = \"utf-8\"\n",
    "        self.dictionary_filename = \"./data_for_predict/word_dict.dic\"\n",
    "        self.chunk_size = 5\n",
    "        self.load_dict()\n",
    "\n",
    "        words = []\n",
    "        for filename in glob.glob(self.corpus_file, recursive=True):\n",
    "            with open(filename, \"r\", encoding=self.corpus_encoding) as f:\n",
    "\n",
    "                # word breaking\n",
    "                text = f.read()\n",
    "                # 全ての文字を小文字に統一し、改行をスペースに変換\n",
    "                text = text.lower().replace(\"\\n\", \" \")\n",
    "                # 特定の文字以外の文字を空文字に置換する\n",
    "                text = re.sub(r\"[^a-z '\\-]\", \"\", text)\n",
    "                # 複数のスペースはスペース一文字に変換\n",
    "                text = re.sub(r\"[ ]+\", \" \", text)\n",
    "\n",
    "                # 前処理： '-' で始まる単語は無視する\n",
    "                words = [ word for word in text.split() if not word.startswith(\"-\")]\n",
    "\n",
    "\n",
    "        self.data_n = len(words) - self.chunk_size\n",
    "        self.data = self.seq_to_matrix(words)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        訓練データとテストデータを準備する。\n",
    "        data_n = ( text データの総単語数 ) - chunk_size\n",
    "        input: (data_n, chunk_size, vocabulary_size)\n",
    "        output: (data_n, vocabulary_size)\n",
    "        \"\"\"\n",
    "\n",
    "        # 入力と出力の次元テンソルを準備\n",
    "        all_input = np.zeros([self.chunk_size, self.vocabulary_size, self.data_n])\n",
    "        all_output = np.zeros([self.vocabulary_size, self.data_n])\n",
    "\n",
    "        # 準備したテンソルに、コーパスの one-hot 表現(self.data) のデータを埋めていく\n",
    "        # i 番目から ( i + chunk_size - 1 ) 番目までの単語が１組の入力となる\n",
    "        # このときの出力は ( i + chunk_size ) 番目の単語\n",
    "        for i in range(self.data_n):\n",
    "            all_output[:, i] = self.data[:, i + self.chunk_size] # (i + chunk_size) 番目の単語の one-hot ベクトル\n",
    "            for j in range(self.chunk_size):\n",
    "                all_input[j, :, i] = self.data[:, i + self.chunk_size - j - 1]\n",
    "\n",
    "        # 後に使うデータ形式に合わせるために転置を取る\n",
    "        all_input = all_input.transpose([2, 0, 1])\n",
    "        all_output = all_output.transpose()\n",
    "\n",
    "        # 訓練データ：テストデータを 4 : 1 に分割する\n",
    "        training_num = ( self.data_n * 4 ) // 5\n",
    "        return all_input[:training_num], all_output[:training_num], all_input[training_num:], all_output[training_num:]\n",
    "\n",
    "\n",
    "    def build_dict(self):\n",
    "        # コーパス全体を見て、単語の出現回数をカウントする\n",
    "        counter = collections.Counter()\n",
    "        for filename in glob.glob(self.corpus_file, recursive=True):\n",
    "            with open(filename, \"r\", encoding=self.corpus_encoding) as f:\n",
    "\n",
    "                # word breaking\n",
    "                text = f.read()\n",
    "                # 全ての文字を小文字に統一し、改行をスペースに変換\n",
    "                text = text.lower().replace(\"\\n\", \" \")\n",
    "                # 特定の文字以外の文字を空文字に置換する\n",
    "                text = re.sub(r\"[^a-z '\\-]\", \"\", text)\n",
    "                # 複数のスペースはスペース一文字に変換\n",
    "                text = re.sub(r\"[ ]+\", \" \", text)\n",
    "\n",
    "                # 前処理： '-' で始まる単語は無視する\n",
    "                words = [word for word in text.split() if not word.startswith(\"-\")]\n",
    "\n",
    "                counter.update(words)\n",
    "\n",
    "        # 出現頻度の低い単語を一つの記号にまとめる\n",
    "        word_id = 0\n",
    "        dictionary = {}\n",
    "        for word, count in counter.items():\n",
    "            if count <= self.unknown_word_threshold:\n",
    "                continue\n",
    "\n",
    "            dictionary[word] = word_id\n",
    "            word_id += 1\n",
    "        dictionary[self.unknown_word_symbol] = word_id\n",
    "\n",
    "        print(\"総単語数：\", len(dictionary))\n",
    "\n",
    "        # 辞書を pickle を使って保存しておく\n",
    "        with open(self.dictionary_filename, \"wb\") as f:\n",
    "            pickle.dump(dictionary, f)\n",
    "            print(\"Dictionary is saved to\", self.dictionary_filename)\n",
    "\n",
    "        self.dictionary = dictionary\n",
    "\n",
    "        print(self.dictionary)\n",
    "\n",
    "    def load_dict(self):\n",
    "        with open(self.dictionary_filename, \"rb\") as f:\n",
    "            self.dictionary = pickle.load(f)\n",
    "            self.vocabulary_size = len(self.dictionary)\n",
    "            self.input_layer_size = len(self.dictionary)\n",
    "            self.output_layer_size = len(self.dictionary)\n",
    "            print(\"総単語数: \", self.input_layer_size)\n",
    "\n",
    "    def get_word_id(self, word):\n",
    "        # print(word)\n",
    "        # print(self.dictionary)\n",
    "        # print(self.unknown_word_symbol)\n",
    "        # print(self.dictionary[self.unknown_word_symbol])\n",
    "        # print(self.dictionary.get(word, self.dictionary[self.unknown_word_symbol]))\n",
    "        return self.dictionary.get(word, self.dictionary[self.unknown_word_symbol])\n",
    "\n",
    "    # 入力された単語を one-hot ベクトルにする\n",
    "    def to_one_hot(self, word):\n",
    "        index = self.get_word_id(word)\n",
    "        data = np.zeros(self.vocabulary_size)\n",
    "        data[index] = 1\n",
    "        return data\n",
    "\n",
    "    def seq_to_matrix(self, seq):\n",
    "        print(seq)\n",
    "        data = np.array([self.to_one_hot(word) for word in seq]) # (data_n, vocabulary_size)\n",
    "        return data.transpose() # (vocabulary_size, data_n)\n",
    "\n",
    "class Language:\n",
    "    \"\"\"\n",
    "    input layer: self.vocabulary_size\n",
    "    hidden layer: rnn_size = 30\n",
    "    output layer: self.vocabulary_size\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.corpus = Corpus()\n",
    "        self.dictionary = self.corpus.dictionary\n",
    "        self.vocabulary_size = len(self.dictionary) # 単語数\n",
    "        self.input_layer_size = self.vocabulary_size # 入力層の数\n",
    "        self.hidden_layer_size = 30 # 隠れ層の RNN ユニットの数\n",
    "        self.output_layer_size = self.vocabulary_size # 出力層の数\n",
    "        self.batch_size = 128 # バッチサイズ\n",
    "        self.chunk_size = 5 # 展開するシーケンスの数。c_0, c_1, ..., c_(chunk_size - 1) を入力し、c_(chunk_size) 番目の単語の確率が出力される。\n",
    "        self.learning_rate = 0.005 # 学習率\n",
    "        self.epochs = 1000 # 学習するエポック数\n",
    "        self.forget_bias = 1.0 # LSTM における忘却ゲートのバイアス\n",
    "        self.model_filename = \"./data_for_predict/predict_model.ckpt\"\n",
    "        self.unknown_word_symbol = self.corpus.unknown_word_symbol\n",
    "\n",
    "    def inference(self, input_data, initial_state):\n",
    "        \"\"\"\n",
    "        :param input_data: (batch_size, chunk_size, vocabulary_size) 次元のテンソル\n",
    "        :param initial_state: (batch_size, hidden_layer_size) 次元の行列\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 重みとバイアスの初期化\n",
    "        hidden_w = tf.Variable(tf.truncated_normal([self.input_layer_size, self.hidden_layer_size], stddev=0.01))\n",
    "        hidden_b = tf.Variable(tf.ones([self.hidden_layer_size]))\n",
    "        output_w = tf.Variable(tf.truncated_normal([self.hidden_layer_size, self.output_layer_size], stddev=0.01))\n",
    "        output_b = tf.Variable(tf.ones([self.output_layer_size]))\n",
    "\n",
    "        # BasicLSTMCell, BasicRNNCell は (batch_size, hidden_layer_size) が chunk_size 数ぶんつながったリストを入力とする。\n",
    "        # 現時点での入力データは (batch_size, chunk_size, input_layer_size) という３次元のテンソルなので\n",
    "        # tf.transpose や tf.reshape などを駆使してテンソルのサイズを調整する。\n",
    "\n",
    "        input_data = tf.transpose(input_data, [1, 0, 2]) # 転置。(chunk_size, batch_size, vocabulary_size)\n",
    "        input_data = tf.reshape(input_data, [-1, self.input_layer_size]) # 変形。(chunk_size * batch_size, input_layer_size)\n",
    "        input_data = tf.matmul(input_data, hidden_w) + hidden_b # 重みWとバイアスBを適用。 (chunk_size, batch_size, hidden_layer_size)\n",
    "        input_data = tf.split(input_data, self.chunk_size, 0) # リストに分割。chunk_size * (batch_size, hidden_layer_size)\n",
    "\n",
    "        # RNN のセルを定義する。RNN Cell の他に LSTM のセルや GRU のセルなどが利用できる。\n",
    "        cell = tf.nn.rnn_cell.BasicRNNCell(self.hidden_layer_size)\n",
    "        outputs, states = tf.nn.static_rnn(cell, input_data, initial_state=initial_state)\n",
    "        \n",
    "        # 最後に隠れ層から出力層につながる重みとバイアスを処理する\n",
    "        # 最終的に softmax 関数で処理し、確率として解釈される。\n",
    "        # softmax 関数はこの関数の外で定義する。\n",
    "        output = tf.matmul(outputs[-1], output_w) + output_b\n",
    "\n",
    "        return output\n",
    "\n",
    "    def loss(self, logits, labels):\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def training(self, cost):\n",
    "        # 今回は最適化手法として Adam を選択する。\n",
    "        # ここの AdamOptimizer の部分を変えることで、Adagrad, Adadelta などの他の最適化手法を選択することができる\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(cost)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def train(self):\n",
    "        # 変数などの用意\n",
    "        input_data = tf.placeholder(\"float\", [None, self.chunk_size, self.input_layer_size])\n",
    "        actual_labels = tf.placeholder(\"float\", [None, self.output_layer_size])\n",
    "        initial_state = tf.placeholder(\"float\", [None, self.hidden_layer_size])\n",
    "\n",
    "        prediction = self.inference(input_data, initial_state)\n",
    "        cost = self.loss(prediction, actual_labels)\n",
    "        optimizer = self.training(cost)\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(actual_labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "        # TensorBoard で可視化するため、クロスエントロピーをサマリーに追加\n",
    "        tf.summary.scalar(\"Cross entropy: \", cost)\n",
    "        summary = tf.summary.merge_all()\n",
    "\n",
    "        # 訓練・テストデータの用意\n",
    "        # corpus = Corpus()\n",
    "        trX, trY, teX, teY = self.corpus.prepare_data()\n",
    "        training_num = trX.shape[0]\n",
    "\n",
    "        # ログを保存するためのディレクトリ\n",
    "        timestamp = time.time()\n",
    "        dirname = datetime.datetime.fromtimestamp(timestamp).strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        # ここから実際に学習を走らせる\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            summary_writer = tf.summary.FileWriter(\"./log/\" + dirname, sess.graph)\n",
    "\n",
    "            # エポックを回す\n",
    "            for epoch in range(self.epochs):\n",
    "                step = 0\n",
    "                epoch_loss = 0\n",
    "                epoch_acc = 0\n",
    "\n",
    "                # 訓練データをバッチサイズごとに分けて学習させる (= optimizer を走らせる)\n",
    "                # エポックごとの損失関数の合計値や（訓練データに対する）精度も計算しておく\n",
    "                while (step + 1) * self.batch_size < training_num:\n",
    "                    start_idx = step * self.batch_size\n",
    "                    end_idx = (step + 1) * self.batch_size\n",
    "\n",
    "                    batch_xs = trX[start_idx:end_idx, :, :]\n",
    "                    batch_ys = trY[start_idx:end_idx, :]\n",
    "\n",
    "                    _, c, a = sess.run([optimizer, cost, accuracy],\n",
    "                                       feed_dict={input_data: batch_xs,\n",
    "                                                  actual_labels: batch_ys,\n",
    "                                                  initial_state: np.zeros([self.batch_size, self.hidden_layer_size])\n",
    "                                                  }\n",
    "                                       )\n",
    "                    epoch_loss += c\n",
    "                    epoch_acc += a\n",
    "                    step += 1\n",
    "\n",
    "                # コンソールに損失関数の値や精度を出力しておく\n",
    "                print(\"Epoch\", epoch, \"completed ouf of\", self.epochs, \"-- loss:\", epoch_loss, \" -- accuracy:\",\n",
    "                      epoch_acc / step)\n",
    "\n",
    "                # Epochが終わるごとにTensorBoard用に値を保存\n",
    "                summary_str = sess.run(summary, feed_dict={input_data: trX,\n",
    "                                                           actual_labels: trY,\n",
    "                                                           initial_state: np.zeros(\n",
    "                                                               [trX.shape[0],\n",
    "                                                                self.hidden_layer_size]\n",
    "                                                           )\n",
    "                                                           }\n",
    "                                       )\n",
    "                summary_writer.add_summary(summary_str, epoch)\n",
    "                summary_writer.flush()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b70925bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_3.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IPythonのインポート\n",
    "from IPython.display import Image\n",
    "# ネット画像のurlを直接開いて表示\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_3.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b4098",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 3.3　確認テスト\n",
    "##### &emsp;&emsp; 　確認テスト①LSTMとCECが抱える課題について、それぞれ簡潔に述べよ。\n",
    "##### &emsp;&emsp; 　解答：\n",
    "##### &emsp;&emsp; 　LSTM  :  パラメータ数が多い。計算量が多い。\n",
    "##### &emsp;&emsp; 　CEC　 : 学習能力がない。(勾配=1)\n",
    "##### &emsp;&emsp; 　確認テスト②LSTMとGRUの違いを簡潔に述べよ。\n",
    "##### &emsp;&emsp; 　解答：\n",
    "##### &emsp;&emsp; 　LSTM  :  ゲート数は３（入力、出力、忘却）。CECが有る。\n",
    "##### &emsp;&emsp; 　GRU :　ゲート数は２（リセット、更新）。CECが無い。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c40ea",
   "metadata": {},
   "source": [
    "###  ４、Section4：双方向RNN\n",
    "####  &emsp;&emsp; 4.1　要点まとめ\n",
    "#### &emsp;&emsp; 過去の情報だけでなく、未来の情報を加味することで精度を向上させるためのモデル\n",
    "#### &emsp;&emsp; 実用例：文章の構成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ace4c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec4_1.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec4_1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf9a65",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 4.2　実装演習結果と考察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "212f17fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec4_2.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 演習チャレンジ\n",
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec4_2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536b33a",
   "metadata": {},
   "source": [
    "###  ５、Section5：Seq2Seq\n",
    "####  &emsp;&emsp; 5.1　要点まとめ\n",
    "\n",
    "####  &emsp;&emsp; Encoder-Decoderモデルの一種。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e637a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/swq2swq.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/swq2swq.jpg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bad685ba",
   "metadata": {},
   "source": [
    "####  以下のUrlの説明がわかりやすかったので、記載しておきます。\n",
    "#####  https://tips-memo.com/translation-jayalmmar-attention\n",
    "####  &emsp;&emsp; Encoder : 単語をRNNに入力していき蓄積いく。文脈の意味ベクトルとして出力する。\n",
    "####  &emsp;&emsp; Encoder : Decoder: encoderから入力された意味ベクトルを別の出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34600c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec5_encode.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec5_encode.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8c810e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec5_encode_MLM.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec5_encode_MLM.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c76e6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec5_decode.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec5_decode.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de734a",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; Seq2seqの課題:\n",
    "####  &emsp;&emsp;   - 課題一問一答しかできない\n",
    "####  &emsp;&emsp;   - 問に対して文脈も何もなく、ただ応答が行われる続ける。\n",
    "####  &emsp;&emsp;  対策：\n",
    "####  &emsp;&emsp; 　　HREDで対応。\n",
    "\n",
    "\n",
    "####  &emsp;&emsp; HREDとは、\n",
    "####  &emsp;&emsp; 　 過去n-1 個の発話から次の発話を生成\n",
    "####  &emsp;&emsp; HREDの構造：\n",
    "####  &emsp;&emsp; 　Seq2Seq+ Context RNN\n",
    "####  &emsp;&emsp; 　　Context RNN: Encoder のまとめた各文章の系列を\n",
    "####  &emsp;&emsp; 　まとめて、これまでの会話コンテキスト全体を表す\n",
    "####  &emsp;&emsp; 　ベクトルに変換する構造。\n",
    "\n",
    "####  &emsp;&emsp; Context RNN：\n",
    "####  &emsp;&emsp; 　過去の発話の履歴を加味した返答をできる。\n",
    "\n",
    "####  &emsp;&emsp; HREDの課題：\n",
    "####  &emsp;&emsp;  - HRED は確率的な多様性が字面にしかなく、会話の「流れ」のような多様性が無い。\n",
    "####  &emsp;&emsp;  - 短く情報量に乏しい答えをしがち　(ex.うん」「そうだね」「・・・」など。) \n",
    "####  &emsp;&emsp;  対策：\n",
    "####  &emsp;&emsp; 　VHREDで対応。\n",
    "\n",
    "####  &emsp;&emsp; VHREDとは、\n",
    "####  &emsp;&emsp; 　HREDに、VAEの潜在変数の概念を追加したもの。\n",
    "####  &emsp;&emsp; 　HREDの課題を、VAEの潜在変数の概念を追加することで解決した構造\n",
    "\n",
    "####  &emsp;&emsp; VAEとは、\n",
    "####  &emsp;&emsp; 　データを潜在変数zの確率分布という構造に\n",
    "####  &emsp;&emsp; 　押し込めることを可能にします。通常のオートエンコーダーの場合、\n",
    "####  &emsp;&emsp; 　何かしら潜在変数zにデータを押し込めているものの、その構造が\n",
    "####  &emsp;&emsp; 　どのような状態かわからない。VAEはこの潜在変数zに確率分布z∼N(0,1)を仮定したもの。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd73eb62",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 5.2　実装演習結果と考察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7333f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec5_xx.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec5_xx.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a77813",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 5.3　確認テスト\n",
    "##### &emsp;&emsp; 　確認テスト①下記の選択肢から、seq2seqについて説明しているものを選べ。\n",
    "##### &emsp;&emsp; 　解答：(2)\n",
    "##### &emsp;&emsp; 　確認テスト②seq2seqとHRED、HREDとVHREDの違いを簡潔に述べよ。\n",
    "##### &emsp;&emsp; 　解答：\n",
    "##### &emsp;&emsp; 　seq2seq : 一問一答の時系列モデル\n",
    "##### &emsp;&emsp; 　HRED: 文脈の意味をくみ取って回答するようにしたもの。\n",
    "##### &emsp;&emsp; 　VHRED: HREDがあたりさわりのない回答をするのに対してVAEの考えを取り入れて改良を加えたもの。\n",
    "##### &emsp;&emsp; 　確認テスト③　VAEに関する下記の説明文中の空欄に当てはまる言葉を答えよ。\n",
    "##### &emsp;&emsp; 　　　自己符号化器の潜在変数に____を導入したもの。\n",
    "##### &emsp;&emsp; 　解答：確率分布\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc39dff",
   "metadata": {},
   "source": [
    "###  ６、Section6：Word2vec\n",
    "####  &emsp;&emsp; 6.1　要点まとめ\n",
    "\n",
    "####  &emsp;&emsp; 　Word2Vecも単語の分散表現の獲得を目指した手法\n",
    "####  &emsp;&emsp; 　「単語の分散表現」とは、単語を固定長のベクトルで表現すること\n",
    "####  &emsp;&emsp; 　単語をベクトルで表現することができれば単語の意味を定量的に把握することができるため、\n",
    "####  &emsp;&emsp; 　様々な処理に応用することが出来る。\n",
    "####  &emsp;&emsp; 　Word2vecで使用するニューラルネットワークのモデル\n",
    "####  &emsp;&emsp;&emsp;&emsp;  　CBOW(continuous bag-of-words)\n",
    "####  &emsp;&emsp;&emsp;&emsp;  　skip-gram\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d6e22",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 6.2　実装演習結果と考察\n",
    "#### 以下のURLを参考にword2vecを演習。\n",
    "https://qiita.com/propella/items/febc423998fd210800ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07d8cf",
   "metadata": {},
   "source": [
    "###  ７、Section7：Attention Mechanism\n",
    "####  &emsp;&emsp; 7.1　要点まとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ec6fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec7.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= 'https://raw.githubusercontent.com/mutsumutsu67/rapid_challenge/main/stage4_day3_sec7.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a194c",
   "metadata": {},
   "source": [
    "####  &emsp;&emsp; 7.2　確認テスト\n",
    "##### &emsp;&emsp; 　確認テスト①　RNNとword2vec、seq2seqとAttentionの違いを簡潔に述べよ。\n",
    "##### &emsp;&emsp; 　解答：\n",
    "##### &emsp;&emsp; 　RNN  :  時系列データ処理に適した手法\n",
    "##### &emsp;&emsp; 　word2vec :　単語分散ベクトルを得る手法\n",
    "##### &emsp;&emsp; 　seq2seq  :  　一つの時系列データから別の時系列データを得る手法\n",
    "##### &emsp;&emsp; 　Attention :　時系列データの中身の関連性に重みをつける"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
